{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c9a5da7",
   "metadata": {},
   "source": [
    "# Exercise 8: Seeing the Brain â€œLearnâ€ through Reward Prediction Errors\n",
    "## A quick look at the MID task\n",
    "\n",
    "Here we move from artificial networks back to human brains, using the **Monetary Incentive Delay (MID)** task. In the MID:\n",
    "\n",
    "1. Participants see a cue predicting potential reward, neutral outcome, or loss.  \n",
    "2. They respond quickly to a target to try to earn money (or avoid losing it).  \n",
    "3. Feedback tells them if they succeeded, generating a **prediction error** when outcome differs from expectation.  \n",
    "\n",
    "> **See â€œGuide to Exercise 8â€ slides** for a step-by-step demo of the MID timing, trial types, and expected brain responses.\n",
    "\n",
    "---\n",
    "\n",
    "## What you will do in this notebook (and why)\n",
    "\n",
    "### 1. **QC Anatomy**  \n",
    "You will load brain images and verify the alignment of your region of interest (ROI)â€”the nucleus accumbens (NAcc).  \n",
    "**Why?**  \n",
    "âœ… To make sure the mask correctly covers the NAcc (more on the mask below). If the mask is off, any measurements from it would not represent true NAcc activity.\n",
    "\n",
    "#### Exploring the NAcc in the ABCD Data Dictionary\n",
    "\n",
    "For a deeper understanding of the nucleus accumbens (NAcc), look up the following metrics in the ABCD data dictionary and visualize them using the Brain Atlas Visualizer:\n",
    "https://abcd.deapscience.com/#/my-datasets/create-dataset\n",
    "\n",
    "1. **mr_y_smri__vol__aseg__ab__lh_sum (and _rh_sum)**\n",
    "   - **What it measures:** Total volume (mmÂ³) of the left/right nucleus accumbens from FreeSurferâ€™s subcortical segmentation.\n",
    "   - **Why itâ€™s useful:** This is the classic structural metricâ€”literally the size of the NAcc. Itâ€™s stable, easy to interpret, and visually clear when you explore the region in the ABCD Brain Atlas Visualizer.\n",
    "\n",
    "2. **mr_y_smri__t1__aseg__ab__lh_mean (and _rh_mean)**\n",
    "   - **What it measures:** Mean T1-weighted intensity within the NAcc (left/right).\n",
    "   - **Why itâ€™s useful:** This reflects tissue contrast and integrity. It isnâ€™t a â€œsizeâ€ measure but a signal measure related to microstructural properties (e.g., myelination, iron content, water density). It provides a complementary way of looking at NAcc structure beyond just volume.\n",
    "---\n",
    "\n",
    "### 2. **Extract NAcc Time-Series**  \n",
    "You will extract the BOLD signal (functional MRI activation) from the NAcc across time. â€œBlood-Oxygen-Level-Dependent (BOLD) signalâ€: this a measure of blood flow to a brain region, which we use as a proxy for neural activity. \n",
    "\n",
    "**Why?**  \n",
    "âœ… To isolate the activity from our key brain region, so we can later connect its behavior to reward anticipation and feedback.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Build Reward vs Neutral Arrays**  \n",
    "You will separate the NAcc activation values into two groups: Reward trials vs Neutral trials.  \n",
    "**Why?**  \n",
    "âœ… To directly compare how strongly the NAcc responds to rewarding cues versus neutral cues, helping test the incentive-salience hypothesis.  \n",
    "ğŸ§  The **incentive-salience hypothesis** proposes that dopamine transforms neutral cues into â€œwantedâ€ signals, giving them motivational power to drive behavior.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Visualizations & Simple Probabilistic Insights**  \n",
    "You will generate several figures:  \n",
    "- Box plot of means  \n",
    "- Violin plot of full distributions  \n",
    "- Empirical probability $P(\\mathrm{Reward} > \\mathrm{Neutral})$  \n",
    "- Bootstrap confidence interval  \n",
    "- Whole-brain activation maps  \n",
    "\n",
    "**Why?**  \n",
    "âœ… Different plots let you see the data from multiple perspectives: central tendency, spread, uncertainty, and brain location.  \n",
    "âœ… Combining visual and statistical approaches builds a stronger, more trustworthy analysis.\n",
    "\n",
    "---\n",
    "\n",
    "Letâ€™s get started! ğŸš€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905d2691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Import Libraries & Configure Environment\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Core libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# fMRI analysis\n",
    "from nilearn import image, masking\n",
    "from nilearn.image import resample_to_img\n",
    "from nilearn.masking import apply_mask\n",
    "\n",
    "# Interactive widgets\n",
    "from ipywidgets import interact\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Network utilities (for data download)\n",
    "import urllib.request\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Configuration\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Display plots inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_theme(context=\"notebook\", style=\"whitegrid\", palette=\"muted\", font_scale=1.2)\n",
    "\n",
    "# Create output folder for figures\n",
    "os.makedirs(\"figs\", exist_ok=True)\n",
    "\n",
    "print(\"âœ… Environment configured successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff413962",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Source, Citation & Folder Layout\n",
    "\n",
    "**ğŸš¨ TEAMWORK NOTE (read carefully!)**  \n",
    "You can work with any of the four available subjects:\n",
    "- **Subject 01:** set `SUBJECT = \"sub-s001\"`  \n",
    "- **Subject 02:** set `SUBJECT = \"sub-s002\"`  \n",
    "- **Subject 03:** set `SUBJECT = \"sub-s003\"`  \n",
    "- **Subject 04:** set `SUBJECT = \"sub-s004\"`  \n",
    "\n",
    "In this exercise we use **real fMRI data** from the Adolescent Health and Development in Context (AHDC) study, publicly available on OpenNeuro:\n",
    "\n",
    "> Baldwin M. Way, Christopher R. Browning, Dylan D. Wagner, Jodi L. Ford, Bethany Boettner & Ping Bai (2025).  \n",
    "> _Structural and functional MRI dataset from the Adolescent Health and Development in Context (AHDC) study in Columbus, Ohio._  \n",
    "> OpenNeuro [Dataset] doi:10.18112/openneuro.ds005901.v1.0.0  \n",
    "> https://github.com/OpenNeuroDatasets/ds005901\n",
    "\n",
    "This dataset was collected as part of a **longitudinal neuroimaging study of adolescent health and development**. Participants completed surveys, smartphone-based ecological momentary assessments, and MRI scans across multiple waves. One aim was to understand how **community exposures and reward processes** shape brain function and substance use risk.\n",
    "\n",
    "We'll focus on the **Monetary Incentive Delay (MID)** task, which measures reward anticipation and outcome processing. You can choose to analyze any of the four subjects' data from the first MID run.\n",
    "\n",
    "> **Before you begin, set `SUBJECT = \"sub-s001\"`, `\"sub-s002\"`, `\"sub-s003\"`, or `\"sub-s004\"`** in the code cell below.\n",
    "\n",
    "Each subject's folder contains:  \n",
    "- a 4D BOLD fMRI volume:  \n",
    "  `sub-s00X_task-mid_run-01_bold.nii.gz`  \n",
    "- its trial timing file:  \n",
    "  `sub-s00X_task-mid_run-01_events.tsv`  \n",
    "- (you'll also need the bilateral NAcc ROI mask: `nacc_bilateral_mask.nii`, placed in the `data/` folder)\n",
    "\n",
    "### Download reliability note (important)\n",
    "\n",
    "OpenNeuroâ€™s â€œsnapshotâ€ download URLs are convenient for version pinning, but they may occasionally return transient **502 Bad Gateway** errors. This notebookâ€™s download code uses a robust fallback order:\n",
    "\n",
    "- **Primary (pinned):** OpenNeuro snapshot URL (uses `SNAPSHOT = \"1.0.0\"`)\n",
    "- **Fallback:** Direct OpenNeuro S3 object URL:  \n",
    "  `https://s3.amazonaws.com/openneuro.org/{DATASET}/{SUBJECT}/func/{bold_fname}`\n",
    "\n",
    "We **do not** use GitHub raw URLs for the BOLD `.nii.gz` file because large OpenNeuro files in that repo are often stored via **git-annex**; the GitHub URL may return a small pointer file rather than real gzip data. (GitHub is still used as a fallback for the small `events.tsv`.)\n",
    "\n",
    "**Expected directory structure (this repo):**\n",
    "\n",
    "```\n",
    "Exercise8/\n",
    "â”œâ”€â”€ Exercise8.ipynb â† This notebook\n",
    "â”œâ”€â”€ figs/ â† Saved figures will go here\n",
    "â””â”€â”€ data/\n",
    "    â”œâ”€â”€ nacc_bilateral_mask.nii\n",
    "    â”œâ”€â”€ qc_nacc_roi_alignment.png â† Static QC image (if provided)\n",
    "    â”œâ”€â”€ sub-s001/\n",
    "    â”œâ”€â”€ sub-s002/\n",
    "    â”œâ”€â”€ sub-s003/\n",
    "    â””â”€â”€ sub-s004/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ea4e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 0. Data folder constants\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Data will be stored in the 'data' subfolder relative to this notebook\n",
    "# This works whether the notebook is opened directly or from the repo root\n",
    "DATA_ROOT = Path(\"data\")\n",
    "\n",
    "print(f\"ğŸ“ Data root: {DATA_ROOT.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef57f72",
   "metadata": {},
   "source": [
    "## Select Your Subject\n",
    "\n",
    "Choose which subject's data you'd like to analyze. Available subjects: sub-s001, sub-s002, sub-s003, sub-s004.\n",
    "\n",
    "> **Set `SUBJECT = \"subâ€‘s001\"`, `\"subâ€‘s002\"`, `\"subâ€‘s003\"`, or `\"subâ€‘s004\"`** in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb19301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to \"sub-s001\", \"sub-s002\", \"sub-s003\", or \"sub-s004\" before you start!\n",
    "SUBJECT = \"sub-s001\"\n",
    "\n",
    "# Pre-defined file paths\n",
    "FUNC_DIR = DATA_ROOT / SUBJECT / \"func\"\n",
    "BOLD = FUNC_DIR / f\"{SUBJECT}_task-mid_run-01_bold.nii\"\n",
    "BOLD_GZ = FUNC_DIR / f\"{SUBJECT}_task-mid_run-01_bold.nii.gz\"\n",
    "EVENT = FUNC_DIR / f\"{SUBJECT}_task-mid_run-01_events.tsv\"\n",
    "MASK = DATA_ROOT / \"nacc_bilateral_mask.nii\"\n",
    "\n",
    "print(\"Selected subject:\", SUBJECT)\n",
    "print(\"  BOLD (uncompressed) â†’\", BOLD)\n",
    "print(\"  BOLD (compressed)   â†’\", BOLD_GZ)\n",
    "print(\"  EVENTS â†’\", EVENT)\n",
    "print(\"  MASK   â†’\", MASK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef825d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Robust data download (OpenNeuro snapshot URL + direct S3 fallback; GitHub fallback for TSV only)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError, URLError\n",
    "\n",
    "DATASET  = \"ds005901\"\n",
    "SNAPSHOT = \"1.0.0\"  # used by OpenNeuro snapshot URLs\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Helpers\n",
    "# --------------------------------------------------------------------\n",
    "def is_gzip_file(path: Path) -> bool:\n",
    "    \"\"\"Return True if file exists and has gzip magic bytes.\"\"\"\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            return f.read(2) == b\"\\x1f\\x8b\"\n",
    "    except OSError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def download_one(url: str, dest: Path) -> bool:\n",
    "    \"\"\"Download URL to dest, streaming in chunks. Returns True on success.\"\"\"\n",
    "    try:\n",
    "        dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with urllib.request.urlopen(url) as r, open(dest, \"wb\") as f:\n",
    "            shutil.copyfileobj(r, f, length=1024 * 1024)\n",
    "        return True\n",
    "    except (HTTPError, URLError) as e:\n",
    "        print(f\"   âš ï¸  failed: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  failed: {type(e).__name__}: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def download_with_fallback(urls: list[str], dest: Path) -> Path | None:\n",
    "    \"\"\"Try URLs in order; returns dest if downloaded, else None.\"\"\"\n",
    "    for i, url in enumerate(urls, start=1):\n",
    "        print(f\"â¬‡ï¸  [{i}/{len(urls)}] {dest.name} â† {url}\")\n",
    "        if download_one(url, dest):\n",
    "            print(\"   â€¦downloaded\")\n",
    "            return dest\n",
    "    return None\n",
    "\n",
    "\n",
    "def ensure_openneuro_py() -> None:\n",
    "    \"\"\"Install openneuro-py once per session if needed.\"\"\"\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            [\"openneuro-py\", \"--help\"],\n",
    "            stdout=subprocess.DEVNULL,\n",
    "            stderr=subprocess.DEVNULL,\n",
    "            check=True,\n",
    "        )\n",
    "    except Exception:\n",
    "        subprocess.run([\"python3\", \"-m\", \"pip\", \"install\", \"-q\", \"openneuro-py\"], check=True)\n",
    "\n",
    "\n",
    "def openneuro_py_download(relpath: str, target_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    relpath example: 'sub-s001/func/sub-s001_task-mid_run-01_bold.nii.gz'\n",
    "    Downloads into target_dir/..., preserving the relpath structure.\n",
    "    \"\"\"\n",
    "    ensure_openneuro_py()\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"openneuro-py\",\n",
    "            \"download\",\n",
    "            f\"--dataset={DATASET}\",\n",
    "            f\"--target-dir={target_dir}\",\n",
    "            f\"--include={relpath}\",\n",
    "        ],\n",
    "        check=True,\n",
    "    )\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Build paths + URLs\n",
    "# --------------------------------------------------------------------\n",
    "FUNC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "events_fname = f\"{SUBJECT}_task-mid_run-01_events.tsv\"\n",
    "bold_fname   = f\"{SUBJECT}_task-mid_run-01_bold.nii.gz\"\n",
    "\n",
    "evt_path     = FUNC_DIR / events_fname\n",
    "bold_path_gz = FUNC_DIR / bold_fname\n",
    "\n",
    "# OpenNeuro \"snapshot\" URLs (sometimes return 502 during outages)\n",
    "openneuro_evt = (\n",
    "    f\"https://openneuro.org/crn/datasets/{DATASET}/snapshots/{SNAPSHOT}/files/\"\n",
    "    f\"{SUBJECT}:func:{events_fname}?download=1\"\n",
    " )\n",
    "openneuro_bold = (\n",
    "    f\"https://openneuro.org/crn/datasets/{DATASET}/snapshots/{SNAPSHOT}/files/\"\n",
    "    f\"{SUBJECT}:func:{bold_fname}?download=1\"\n",
    " )\n",
    "\n",
    "# Direct S3 URLs (often work even if OpenNeuro web/API is down)\n",
    "s3_evt  = f\"https://s3.amazonaws.com/openneuro.org/{DATASET}/{SUBJECT}/func/{events_fname}\"\n",
    "s3_bold = f\"https://s3.amazonaws.com/openneuro.org/{DATASET}/{SUBJECT}/func/{bold_fname}\"\n",
    "\n",
    "# GitHub raw: OK for TSV; DO NOT use GitHub raw for .nii.gz (git-annex pointer)\n",
    "github_evt = f\"https://github.com/OpenNeuroDatasets/{DATASET}/raw/main/{SUBJECT}/func/{events_fname}\"\n",
    "\n",
    "events_urls = [openneuro_evt, s3_evt, github_evt]\n",
    "bold_urls   = [openneuro_bold, s3_bold]\n",
    "\n",
    "print(f\"ğŸ” Checking data files for {SUBJECT}â€¦\")\n",
    "\n",
    "# EVENTS\n",
    "if evt_path.exists() and evt_path.stat().st_size > 0:\n",
    "    print(f\"âœ… {events_fname} already exists, skipping download.\")\n",
    "    EVENT = evt_path\n",
    "else:\n",
    "    EVENT = download_with_fallback(events_urls, evt_path)\n",
    "\n",
    "# BOLD\n",
    "if bold_path_gz.exists() and is_gzip_file(bold_path_gz):\n",
    "    print(f\"âœ… {bold_fname} already exists and is gzip, skipping download.\")\n",
    "    bold_gz = bold_path_gz\n",
    "else:\n",
    "    bold_gz = download_with_fallback(bold_urls, bold_path_gz)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Download events.tsv\n",
    "# --------------------------------------------------------------------\n",
    "print(f\"ğŸ” Checking data files for {SUBJECT}â€¦\")\n",
    "EVENT = download_with_fallback(events_urls, evt_path)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Download BOLD (large) + verify gzip\n",
    "# --------------------------------------------------------------------\n",
    "bold_gz = download_with_fallback(bold_urls, bold_path_gz)\n",
    "\n",
    "# If somehow a non-gzip file landed at the destination, delete it\n",
    "if bold_gz and not is_gzip_file(bold_gz):\n",
    "    print(\"ğŸ§ª The downloaded BOLD file is not gzip. Deleting it.\")\n",
    "    try:\n",
    "        os.remove(bold_gz)\n",
    "    except OSError:\n",
    "        pass\n",
    "    bold_gz = None\n",
    "\n",
    "# If direct URL routes failed, try openneuro-py (may also fail during OpenNeuro outages)\n",
    "if bold_gz is None:\n",
    "    try:\n",
    "        print(\"ğŸ” Trying OpenNeuro via openneuro-pyâ€¦\")\n",
    "        rel = f\"{SUBJECT}/func/{bold_fname}\"\n",
    "        openneuro_py_download(rel, target_dir=str(DATA_ROOT))\n",
    "        if bold_path_gz.exists() and is_gzip_file(bold_path_gz):\n",
    "            bold_gz = bold_path_gz\n",
    "        else:\n",
    "            bold_gz = None\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ openneuro-py download failed: {e}\")\n",
    "        bold_gz = None\n",
    "\n",
    "BOLD = Path(bold_gz) if bold_gz else None\n",
    "\n",
    "print(\"\\n======================================================================\")\n",
    "print(\"ğŸ“ File paths:\")\n",
    "print(f\"  BOLD:   {BOLD} (exists: {bool(BOLD and BOLD.exists())})\")\n",
    "print(f\"  EVENTS: {EVENT} (exists: {bool(EVENT and EVENT.exists())})\")\n",
    "print(f\"  MASK:   {MASK} (exists: {MASK.exists()})\")\n",
    "\n",
    "assert EVENT and EVENT.exists(), \"Missing events.tsv after download.\"\n",
    "assert BOLD and BOLD.exists(),  \"Missing BOLD .nii.gz after download.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39574601",
   "metadata": {},
   "source": [
    "## 1. QC Anatomy & File Sanity Checks\n",
    "\n",
    "Before analyzing brain activity, it's important to confirm that our data are correctly loaded and properly aligned. In the cell below we:\n",
    "\n",
    "1. **Define file paths** to the subject's BOLD fMRI scan, the events timing file, and the NAcc region-of-interest (ROI) mask.  \n",
    "2. **Check** that each file exists on your computer.  \n",
    "3. **Compute** a mean image from the 4D BOLD volume to give a single, easy-to-view anatomical image.  \n",
    "4. **Overlay** the ROI mask (in blue) and a marker for the Ventral Tegmental Area (VTA) (in yellow) to check alignment.\n",
    "\n",
    "**What is the \"mask\"?**  \n",
    "A **mask** in fMRI is a simplified image used to isolate specific brain regions for analysis. It acts like a stencil or cookie-cutter: white areas highlight the voxels to include (e.g., the nucleus accumbens), and black areas hide everything else. By checking the mask placement on the mean image, we ensure we're analyzing the correct brain structure before diving into the data.\n",
    "\n",
    "This quality control step helps prevent misleading results caused by misaligned ROIs or missing files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e480eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# QC: file checks + generate a REAL NAcc ROI overlay on mean functional\n",
    "# (replaces the two older cells)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nilearn import image, plotting\n",
    "from PIL import Image as PILImage\n",
    "from IPython.display import display\n",
    "\n",
    "print(f\"ğŸ“Š Analyzing: {SUBJECT}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  BOLD   exists? {BOLD.exists()}  -> {BOLD}\")\n",
    "print(f\"  EVENTS exists? {EVENT.exists()} -> {EVENT}\")\n",
    "print(f\"  MASK   exists? {MASK.exists()}  -> {MASK}\")\n",
    "\n",
    "# Stop early if anything required is missing\n",
    "missing_files = []\n",
    "if not BOLD.exists():\n",
    "    missing_files.append((\"BOLD\", BOLD))\n",
    "if not EVENT.exists():\n",
    "    missing_files.append((\"EVENTS\", EVENT))\n",
    "if not MASK.exists():\n",
    "    missing_files.append((\"MASK\", MASK))\n",
    "\n",
    "if missing_files:\n",
    "    print(\"\\nâŒ Missing required files:\")\n",
    "    for label, path in missing_files:\n",
    "        print(f\"  - {label}: {path}\")\n",
    "\n",
    "    print(\"\\nFixes:\")\n",
    "    print(\"  - Re-run the download cell above to fetch BOLD and EVENTS.\")\n",
    "    print(\"  - Confirm the instructor-provided MASK is present in the data folder.\")\n",
    "    raise FileNotFoundError(\"Required files missing; cannot generate QC figure.\")\n",
    "\n",
    "print(\"\\nâœ… All required files found. Generating a real QC overlay figure...\")\n",
    "\n",
    "# Helper: compute mask center-of-mass (mm) for sensible cut coordinates\n",
    "def mask_center_mm(mask_path):\n",
    "    m = nib.load(str(mask_path))\n",
    "    data = m.get_fdata() > 0\n",
    "    ijk = np.argwhere(data)\n",
    "    if ijk.size == 0:\n",
    "        return (0.0, 0.0, 0.0)\n",
    "    com_ijk = ijk.mean(axis=0)\n",
    "    com_xyz = nib.affines.apply_affine(m.affine, com_ijk)\n",
    "    return (float(com_xyz[0]), float(com_xyz[1]), float(com_xyz[2]))\n",
    "\n",
    "# Helper: parse task/run from filename for a clearer title\n",
    "def parse_task_run(fname):\n",
    "    task = None\n",
    "    run = None\n",
    "    for part in fname.split(\"_\"):\n",
    "        if part.startswith(\"task-\"):\n",
    "            task = part.replace(\"task-\", \"\")\n",
    "        if part.startswith(\"run-\"):\n",
    "            run = part.replace(\"run-\", \"\")\n",
    "    return task, run\n",
    "\n",
    "task, run = parse_task_run(BOLD.name)\n",
    "task_str = \"MID task\" if task == \"mid\" else (f\"task-{task}\" if task else \"task\")\n",
    "run_str = f\"run-{run}\" if run else \"run\"\n",
    "\n",
    "cut_coords = mask_center_mm(MASK)\n",
    "qc_image_path = DATA_ROOT / \"qc_nacc_roi_alignment.png\"\n",
    "\n",
    "# Always generate (overwrite) so the QC image is real, not a placeholder\n",
    "mean_func = image.mean_img(str(BOLD))\n",
    "disp = plotting.plot_roi(\n",
    "    str(MASK),\n",
    "    bg_img=mean_func,\n",
    "    title=f\"QC: Verify NAcc ROI alignment (mean fMRI, {SUBJECT}, {task_str}, {run_str})\",\n",
    "    display_mode=\"ortho\",\n",
    "    cut_coords=cut_coords,\n",
    "    draw_cross=True,\n",
    ")\n",
    "disp.savefig(str(qc_image_path), dpi=250)\n",
    "disp.close()\n",
    "\n",
    "print(f\"\\nğŸ“ QC figure saved to: {qc_image_path}\")\n",
    "print(f\"   Cut coordinates (mm): x={cut_coords[0]:.1f}, y={cut_coords[1]:.1f}, z={cut_coords[2]:.1f}\")\n",
    "display(PILImage.open(qc_image_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96518fe",
   "metadata": {},
   "source": [
    "### Interpreting the QC Image & Checklist\n",
    "\n",
    "**Static QC Image shows:**\n",
    "- **Anatomical Brain Slices:** Three orthogonal (coronal, sagittal, axial) views of the MNI brain template.\n",
    "- **Crosshairs & Coordinates:** White crosshairs intersect at the approximate NAcc centre (MNI: â€“8, 0, 8).\n",
    "- **Orientation:** â€œLâ€ and â€œRâ€ indicate left/right hemispheres in neurological convention.\n",
    "\n",
    "**âœ… QC Checklist - Verify before proceeding:**\n",
    "1. All three files (BOLD, EVENT, MASK) exist and are accessible.  \n",
    "2. The crosshairs sit over the ventral striatum region (just below the anterior commissure).  \n",
    "3. The intersection point matches both left and right NAcc locations.  \n",
    "4. The displayed coordinates make anatomical sense relative to known brain landmarks.  \n",
    "\n",
    "> **Why this QC step matters:**  \n",
    "> By confirming file accessibility and visually checking that the crosshairs are positioned in the ventral striatum, you ensure that the time-series you extract in the next step actually comes from the intended anatomical region. If the alignment or coordinates are off, all downstream comparisons (Reward vs Neutral) could be invalid.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233d45e1",
   "metadata": {},
   "source": [
    "## 2. Extract NAcc Time-Series\n",
    "\n",
    "Before we dive in, let's simplify **TR** (Repetition Time):\n",
    "\n",
    "> **TR = the interval between \"snapshots.\"**  \n",
    "> Every TR seconds (e.g. 2 s) the scanner takes one full 3D \"photo\" of your brain. When we want the BOLD signal right after an event, we convert the event time (in seconds) into which snapshot number (TR index) to pull.\n",
    "\n",
    "In the cell below we use a helper function `extract_psc()` that:\n",
    "\n",
    "1. **Loads** the 4D BOLD time-series image\n",
    "2. **Resamples the ROI mask** to match the BOLD data's voxel grid and coordinate system  \n",
    "   ğŸ§  This ensures each mask voxel correctly overlaps with corresponding BOLD voxels\n",
    "3. **Applies the mask** to extract BOLD values from NAcc voxels across all time points  \n",
    "   ğŸ¯ Isolates the signal over time from just the NAccâ€”ignoring everything else in the brain\n",
    "4. **Averages across voxels** at each TR to produce a single NAcc time-series  \n",
    "5. **Converts to percent-signal-change (PSC)** for standardized, interpretable units\n",
    "\n",
    "The function returns both:\n",
    "- `nacc_psc`: percent-signal-change time-series (for analysis)\n",
    "- `nacc_ts`: raw signal time-series (for reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a223100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 2. Extract NAcc time-series\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def extract_psc(ts_img, mask_img):\n",
    "    \"\"\"\n",
    "    Helper function to extract percent-signal-change time-series from an ROI.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ts_img : str or Nifti-like\n",
    "        Path to 4D BOLD time-series image\n",
    "    mask_img : str or Nifti-like  \n",
    "        Path to binary ROI mask\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    psc_ts : numpy.ndarray\n",
    "        1D array of percent-signal-change values (one per TR)\n",
    "    raw_ts : numpy.ndarray\n",
    "        1D array of raw signal values (one per TR)\n",
    "    \"\"\"\n",
    "    # Load the 4D BOLD image\n",
    "    bold_img = image.load_img(str(ts_img))\n",
    "    \n",
    "    # Resample mask to BOLD space (nearest-neighbor keeps it binary)\n",
    "    mask_res = resample_to_img(\n",
    "        source_img=str(mask_img),\n",
    "        target_img=bold_img,\n",
    "        interpolation=\"nearest\"\n",
    "    )\n",
    "    \n",
    "    # Extract time-series from all voxels in the mask\n",
    "    # apply_mask returns array of shape (n_volumes, n_voxels)\n",
    "    roi_vox_ts = apply_mask(bold_img, mask_res)\n",
    "    \n",
    "    # Average across voxels to get single ROI trace per TR\n",
    "    # result is 1D array of length n_volumes\n",
    "    raw_ts = roi_vox_ts.mean(axis=1)\n",
    "    \n",
    "    # Convert to percent-signal-change (PSC)\n",
    "    baseline = raw_ts.mean()\n",
    "    psc_ts = 100 * (raw_ts - baseline) / baseline\n",
    "    \n",
    "    print(f\"Extracted time-series length: {len(psc_ts)} TRs\")\n",
    "    print(f\"Baseline mean signal = {baseline:.1f}; converted to PSC.\")\n",
    "    \n",
    "    return psc_ts, raw_ts\n",
    "\n",
    "# 2a) Extract NAcc time-series using our helper function\n",
    "nacc_psc, nacc_ts = extract_psc(BOLD, MASK)\n",
    "\n",
    "# 2b) Quick peek: show first k rows of the PSC time-series in a table\n",
    "df_nacc = pd.DataFrame(nacc_psc, columns=[\"psc_nacc\"])\n",
    "\n",
    "# interactive slider to choose how many rows to display\n",
    "interact(\n",
    "    lambda k: df_nacc.head(k),\n",
    "    k=(1, min(20, len(df_nacc)), 1)  # slider from 1 up to 20 (or total TRs if fewer)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d576f363",
   "metadata": {},
   "source": [
    "### What just happened?\n",
    "\n",
    "- **Raw â†’ PSC:** We calculated the average NAcc signal across the entire run (`baseline`), then converted each TRâ€™s mean activation into **percent-signal-change** (`nacc_psc`). Now â€œ0 %â€ means no change from baseline, and â€œ+1 %â€ means a 1 % increase.\n",
    "- **What is PSC?** **Percent-Signal-Change (PSC)** expresses each TRâ€™s BOLD signal as a percentage change from its baseline, effectively measuring the percent change in blood flow (and thus neural activity) within your ROI (Brain Region of Interest).\n",
    "- **Interactive preview:** The slider lets you inspect the first k rows of the PSC time-series. Try moving it between 1 and 20 (or more) to see how NAcc activation evolves over those snapshots.\n",
    "- **Why PSC?** Converting to percent-signal-change puts all activation values on an intuitive, comparable scaleâ€”standard practice in fMRIâ€”so your subsequent plots speak in â€œpercent changeâ€ rather than arbitrary intensities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ab73a3",
   "metadata": {},
   "source": [
    "## 3. Build Reward vs Neutral Arrays\n",
    "\n",
    "In this step we:\n",
    "\n",
    "- **Load** the MID events file and read each trial's onset time (in seconds) and `trial_type`.\n",
    "- **Convert** each onset time to a TR index, then add a **4â€“5 TR lag** to capture the hemodynamic peak.\n",
    "- **Average** the BOLD signal over the following **2 TRs** to get one activation value per trial.\n",
    "- **Restrict to cue epochs** by filtering rows that start with `Cue_` â€” this isolates the **anticipation** period (aligns with ABCD MID ARvN betas).\n",
    "- **Classify** `Cue_*Reward*` trials into `reward_vals` and `Cue_Triangle` trials into `neutral_vals`.\n",
    "\n",
    "At the end you'll have two lists (`reward_vals` and `neutral_vals`) ready for plotting and probabilistic comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be00f052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 3. Build Reward vs Neutral arrays (using PSC time-series)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# 3a) Load events.tsv\n",
    "events = pd.read_csv(str(EVENT), sep='\\t')\n",
    "print(events[['onset', 'trial_type']].head())\n",
    "\n",
    "# 3b) Get TR from header\n",
    "TR = image.load_img(str(BOLD)).header.get_zooms()[3]\n",
    "print(f\"Repetition time (TR) = {TR} s\")\n",
    "\n",
    "# 3c) Define a helper to sample NAcc PSC after onset\n",
    "def get_activation(ts, onset, lag_TRs=5, win_TRs=2, TR=1.0):\n",
    "    \"\"\"\n",
    "    Return mean NAcc percent-signal-change in the window \n",
    "    [onset+lag, onset+lag+win) measured in TRs.\n",
    "    \"\"\"\n",
    "    onset_TR = int(onset / TR)\n",
    "    start = onset_TR + lag_TRs\n",
    "    end = start + win_TRs\n",
    "    return ts[start:end].mean()\n",
    "\n",
    "# 3d) Restrict to cue epochs (anticipation). Build reward vs neutral lists\n",
    "reward_vals = []\n",
    "neutral_vals = []\n",
    "\n",
    "cue_events = events[events['trial_type'].str.startswith('Cue')]\n",
    "\n",
    "for _, trial in cue_events.iterrows():\n",
    "    act = get_activation(\n",
    "        nacc_psc,               # using percentâ€signalâ€change series\n",
    "        trial['onset'],\n",
    "        lag_TRs=5,\n",
    "        win_TRs=2,\n",
    "        TR=TR\n",
    "    )\n",
    "    if 'Reward' in trial['trial_type']:\n",
    "        reward_vals.append(act)\n",
    "    elif 'Triangle' in trial['trial_type']:\n",
    "        neutral_vals.append(act)\n",
    "\n",
    "# 3e) Quick sanity check\n",
    "print(f\"â†’ {len(reward_vals)} reward CUE trials\")\n",
    "print(f\"â†’ {len(neutral_vals)} neutral (Triangle) CUE trials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78569be7",
   "metadata": {},
   "source": [
    "**What this output tells us**:\n",
    "\n",
    "- The first five rows confirm weâ€™ve correctly loaded the event file, showing each trialâ€™s onset time (in seconds) and its type.\n",
    "- The **Repetition time (TR) = 1.0 s** means the scanner collected one wholeâ€brain volume every second.\n",
    "- We found **80 â€œRewardâ€ trials** and **40 â€œTriangleâ€ (neutral) trials**.  \n",
    "  These counts become the lengths of our two listsâ€”`reward_vals` (80 samples) and `neutral_vals` (40 samples)â€”which weâ€™ll compare in the next steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e50b0e",
   "metadata": {},
   "source": [
    "### Quick Check: Compute Percent-Signal-Change Means\n",
    "\n",
    "Now that weâ€™ve converted our time-series to percent-signal-change (`nacc_psc`), letâ€™s compute the average PSC for each condition.\n",
    "\n",
    "ğŸ§  **First try writing the code without AI (eg, GitHub Copilot)**â€”this helps you internalize the syntax.  \n",
    "ğŸ¤– **If you get stuck**, let Copilot suggest a hint or fill in the blanks.\n",
    "\n",
    "Below, fill in the two lines to calculate:\n",
    "\n",
    "- `mean_reward`: the average PSC of all NAcc values on **Reward** trials  \n",
    "- `mean_neutral`: the average PSC of all NAcc values on **Neutral (Triangle)** trials  \n",
    "\n",
    "Finally, print their difference (`mean_reward - mean_neutral`) to see how much higher (or lower) the Reward response is compared to Neutral.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807684a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Student TO-DO: fill in the two lines below ---\n",
    "mean_reward  = ...   # <- your code here\n",
    "mean_neutral = ...   # <- your code here\n",
    "\n",
    "print(\"Î” mean (Reward â€“ Neutral) =\", mean_reward - mean_neutral)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52d20d7",
   "metadata": {},
   "source": [
    "## 4.Â Visualisations\n",
    "\n",
    "Below are the key plots you will generate.  Each cell saves its figure into `figs/` so you can easily pull them into your writeâ€‘up. The **Figs** folder is in the same folder as this file alongside our datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fcfb6c",
   "metadata": {},
   "source": [
    "### 4a) Event-Locked NAcc Time Course\n",
    "\n",
    "Before comparing trial-averaged activations, let's visualize **when** the NAcc responds to cues by plotting the full time course around cue onset.\n",
    "\n",
    "**What this plot shows:**\n",
    "- **X-axis:** Time relative to cue presentation (seconds). Zero marks the moment the cue appears.\n",
    "- **Y-axis:** NAcc percent-signal-change (PSC), averaged across all trials of each type.\n",
    "- **Shaded bands:** Standard error across trialsâ€”wider bands indicate more variability between individual trials.\n",
    "\n",
    "**Why this matters:**\n",
    "- The **hemodynamic response** peaks ~5â€“7 seconds after a stimulus due to blood flow delays.\n",
    "- By extracting a **peri-stimulus window** (2 TRs before to 14 TRs after cue onset), we capture the full rise, peak, and return-to-baseline of the BOLD signal.\n",
    "- If the Reward curve (orange) rises higher than Neutral (blue) around 5â€“7 seconds post-cue, it confirms that **anticipation**â€”not just outcomeâ€”drives NAcc activation.\n",
    "\n",
    "This temporal view complements the box plot (which collapses time) by showing the **dynamics** of reward processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfabae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Build peri-stimulus time courses for Reward vs Neutral cues\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "win_pre, win_post = 2, 14   # TRs before/after cue\n",
    "t = np.arange(-win_pre, win_post) * TR\n",
    "\n",
    "\n",
    "def extract_epoch(ts, onset_s, TR, pre, post):\n",
    "    onset_TR = int(onset_s / TR)\n",
    "    idx = np.arange(onset_TR - pre, onset_TR + post)\n",
    "    valid = (idx >= 0) & (idx < len(ts))\n",
    "    out = np.full(idx.shape, np.nan, dtype=float)\n",
    "    out[valid] = ts[idx[valid]]\n",
    "    return out\n",
    "\n",
    "cue_reward_onsets = cue_events[cue_events['trial_type'].str.contains('Reward')]['onset'].values\n",
    "cue_neutral_onsets = cue_events[cue_events['trial_type'].str.contains('Triangle')]['onset'].values\n",
    "\n",
    "epochs_reward = np.vstack([extract_epoch(nacc_psc, o, TR, win_pre, win_post) for o in cue_reward_onsets])\n",
    "epochs_neutral = np.vstack([extract_epoch(nacc_psc, o, TR, win_pre, win_post) for o in cue_neutral_onsets])\n",
    "\n",
    "m_reward = np.nanmean(epochs_reward, axis=0)\n",
    "m_neutral = np.nanmean(epochs_neutral, axis=0)\n",
    "se_reward = np.nanstd(epochs_reward, axis=0) / np.sqrt(np.sum(~np.isnan(epochs_reward), axis=0))\n",
    "se_neutral = np.nanstd(epochs_neutral, axis=0) / np.sqrt(np.sum(~np.isnan(epochs_neutral), axis=0))\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(t, m_neutral, color=\"C0\", label=\"Neutral cue\")\n",
    "plt.fill_between(t, m_neutral - se_neutral, m_neutral + se_neutral, color=\"C0\", alpha=0.2)\n",
    "plt.plot(t, m_reward, color=\"C1\", label=\"Reward cue\")\n",
    "plt.fill_between(t, m_reward - se_reward, m_reward + se_reward, color=\"C1\", alpha=0.2)\n",
    "plt.axvline(0, color=\"k\", linestyle=\":\", linewidth=1)\n",
    "plt.xlabel(\"Time from cue (s)\")\n",
    "plt.ylabel(\"NAcc PSC (%)\")\n",
    "plt.title(\"Event-locked NAcc PSC around cue onset\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figs/anticipation_timecourse.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d44cdb7",
   "metadata": {},
   "source": [
    "### Interpreting the Event-Locked Timecourse\n",
    "\n",
    "**What to look for:**\n",
    "1. **Baseline period (âˆ’2 to 0 s):** Both curves should hover near zero PSC before the cue appearsâ€”confirming our PSC baseline is valid.\n",
    "2. **Rise phase (0 to ~5 s):** Both curves climb as blood flows to the NAcc in response to the cue, but does one rise faster or higher?\n",
    "3. **Peak (~5â€“7 s):** The maximum PSC typically occurs here due to the hemodynamic lag. Look for separation between Reward and Neutral traces.\n",
    "4. **Return to baseline (>10 s):** Both curves should descend back toward zero as the anticipation period ends.\n",
    "\n",
    "**Key observations:**\n",
    "- **Reward > Neutral during anticipation:** If the orange line stays consistently above blue during the 4â€“8 second window, it confirms that reward cues elicit **stronger anticipatory activation** in the NAccâ€”the neural signature of incentive salience.\n",
    "- **Standard error bands:** Overlapping bands indicate high trial-to-trial variability, common in single-subject analyses. At the group level (many subjects), these bands typically separate more clearly.\n",
    "- **Timing validates our lag_TRs choice:** The 5-TR lag we used for `get_activation()` samples the peak of this response curve, ensuring we capture maximum anticipation-related activity.\n",
    "\n",
    "This plot bridges the gap between raw time-series (Section 2) and summary statistics (next sections), showing that the NAcc \"wakes up\" specifically when rewards are anticipated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a387a9",
   "metadata": {},
   "source": [
    "### Box Plot with Mean Lines\n",
    "\n",
    "Here weâ€™ll draw a box plot of Reward vs Neutral activations and overlay horizontal lines at the condition means you computed above (`mean_reward`, `mean_neutral`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b92ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Box plot with mean lines\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "# 4a) boxplot\n",
    "sns.boxplot(data=[neutral_vals, reward_vals],\n",
    "            palette=[\"C0\",\"C1\"],\n",
    "            showfliers=False)\n",
    "\n",
    "# overlay the means\n",
    "plt.hlines(mean_neutral, -0.4, 0.4, color=\"C0\", linestyle=\"--\",\n",
    "           label=f\"Neutral mean ({mean_neutral:.2f}%)\")\n",
    "plt.hlines(mean_reward,  0.6, 1.4,  color=\"C1\", linestyle=\"--\",\n",
    "           label=f\"Reward mean ({mean_reward:.2f}%)\")\n",
    "\n",
    "plt.xticks([0,1], [\"Neutral cue\",\"Reward cue\"])\n",
    "plt.ylabel(\"NAcc percent signal change (%)\")\n",
    "plt.title(\"4a) NAcc PSC by cue type (box + means)\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.savefig(\"figs/4a_box_means.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f38bcb2",
   "metadata": {},
   "source": [
    "**Interpretation.**  \n",
    "- The box represents the interquartile range (IQR) of activations; whiskers extend to Â±1.5Ã—IQR.  \n",
    "- Dashed lines mark your previously computed meansâ€”now itâ€™s clear how far Rewardâ€™s mean sits above Neutralâ€™s.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf5825a",
   "metadata": {},
   "source": [
    "### Bootstrap Confidence Interval & Effect Size\n",
    "\n",
    "Now let's quantify the **uncertainty** and **magnitude** of the Reward vs Neutral difference using two complementary statistics:\n",
    "\n",
    "**What this analysis does:**\n",
    "1. **Bootstrap resampling (5,000 iterations):** Randomly samples with replacement from your reward and neutral trial data to simulate what would happen if you ran this experiment thousands of times. This generates a distribution of possible mean differences.\n",
    "2. **95% Confidence Interval (CI):** The range within which we're 95% confident the true population mean difference falls. If this interval excludes zero, the effect is statistically significant.\n",
    "3. **Cohen's d:** A standardized effect size that measures the difference in means relative to the pooled standard deviation. This tells us whether the difference is practically meaningful, not just statistically detectable.\n",
    "\n",
    "**Why both metrics matter:**\n",
    "- **CI answers:** \"How certain are we about the direction and magnitude of the effect?\"\n",
    "- **Cohen's d answers:** \"How large is this effect in real-world terms?\"\n",
    "\n",
    "**Interpreting the output:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08cf839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Bootstrap CI and Cohen's d effect size summary\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "B = 5000\n",
    "boot_diff = []\n",
    "for _ in range(B):\n",
    "    r = rng.choice(reward_vals, size=len(reward_vals), replace=True)\n",
    "    n = rng.choice(neutral_vals, size=len(neutral_vals), replace=True)\n",
    "    boot_diff.append(r.mean() - n.mean())\n",
    "ci_lo, ci_hi = np.percentile(boot_diff, [2.5, 97.5])\n",
    "\n",
    "def cohens_d(a, b):\n",
    "    a, b = np.asarray(a), np.asarray(b)\n",
    "    s1, s2 = a.std(ddof=1), b.std(ddof=1)\n",
    "    sp = np.sqrt(((len(a)-1)*s1**2 + (len(b)-1)*s2**2) / (len(a)+len(b)-2))\n",
    "    return (a.mean() - b.mean()) / sp\n",
    "\n",
    "d = cohens_d(reward_vals, neutral_vals)\n",
    "print(f\"Î” mean = {mean_reward - mean_neutral:.3f}%  (95% CI [{ci_lo:.3f}, {ci_hi:.3f}]),  Cohen's d = {d:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f253fc",
   "metadata": {},
   "source": [
    "### Interpreting Bootstrap CI & Cohen's d\n",
    "\n",
    "**Understanding the printed statistics:**\n",
    "\n",
    "| Statistic | Interpretation |\n",
    "|-----------|----------------|\n",
    "| **Î” mean = X.XX%** | Average difference in NAcc PSC between Reward and Neutral cues across all trials. Positive = Reward higher. |\n",
    "| **95% CI [lo, hi]** | We're 95% confident the true mean difference lies in this range. If both bounds are positive (> 0), Reward significantly exceeds Neutral. |\n",
    "| **Cohen's d** | Standardized effect size:<br>â€¢ **d < 0.2:** Trivial effect<br>â€¢ **0.2â€“0.5:** Small effect<br>â€¢ **0.5â€“0.8:** Medium effect<br>â€¢ **d > 0.8:** Large effect |\n",
    "\n",
    "**What this tells us:**\n",
    "- **If CI excludes zero (e.g., [0.05, 0.31]):** The reward anticipation effect is **statistically reliable**â€”even accounting for trial-to-trial noise, we'd expect Reward cues to consistently activate NAcc more than Neutral cues.\n",
    "- **If d â‰ˆ 0.3â€“0.5:** The effect is **small to medium** in magnitudeâ€”detectable, but subject to individual differences and measurement noise (typical for single-subject fMRI).\n",
    "- **If d > 0.5:** The effect is **moderate to large**â€”reward cues drive a substantial difference in NAcc activation, supporting the incentive-salience hypothesis even at the individual level.\n",
    "\n",
    "**Connecting to neuroscience:**\n",
    "This quantitative summary bridges the visual patterns (timecourse, box plot) and the underlying biology: a Cohen's d of 0.4â€“0.6 suggests that dopamine-driven anticipation produces a **moderate but consistent shift** in NAcc activityâ€”exactly what we'd predict if the brain is learning to \"want\" reward-predicting cues more over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc0d29f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5 Â· Key Take-Aways    \n",
    "\n",
    "### What did we see in the MID task?\n",
    "\n",
    "**Main finding:** The NAcc showed **higher activation for Reward vs Neutral cues** during the anticipation window.\n",
    "\n",
    "| Evidence | What it means |\n",
    "|----------|---------------|\n",
    "| **Event-locked timecourse** | Reward cues (orange) peaked higher than Neutral cues (blue) ~5â€“7 seconds post-cueâ€”exactly when anticipation is strongest. |\n",
    "| **Box plot + means** | Reward trials showed consistently higher PSC, with the mean difference captured by the dashed lines. |\n",
    "| **Bootstrap CI & Cohen's d** | The 95% CI excluded zero (statistically reliable effect), and Cohen's d quantified a small-to-medium effect size typical of single-subject fMRI. |\n",
    "\n",
    "**In plain language:** When the \"win-money\" cue appeared, the nucleus accumbensâ€”the brain's \"want-it\" hubâ€”showed a larger percent-signal-change than when the neutral cue appeared. This is the neural signature of **incentive salience**.\n",
    "\n",
    "---\n",
    "\n",
    "### How does this link back to *BuildingABrain.ipynb*?\n",
    "\n",
    "Both your toy neural network and the human brain use the same three-step loop to learn from rewards:\n",
    "\n",
    "| Step | Artificial Network | Human Brain |\n",
    "|------|-------------------|-------------|\n",
    "| **1. Teaching signal** | Computes prediction error after each guess â†’ updates weights | VTA dopamine burst when outcome > expectation â†’ modulates synapses |\n",
    "| **2. Value learning** | Weights strengthen toward rewarded choices across training epochs | Cortico-striatal synapses strengthen with repeated reward â†’ NAcc \"wants\" cue more |\n",
    "| **3. Behavioral output** | Network selects higher-valued class at test time | Elevated NAcc activity drives faster responses when money is at stake |\n",
    "\n",
    "---\n",
    "\n",
    "### Why does it matter?\n",
    "\n",
    "**Mechanistic insight:**  \n",
    "Seeing NAcc PSC rise after reward cues provides a concrete, measurable readout of the abstract \"prediction-error learning\" you coded in BuildingABrain. The same computational principlesâ€”**error signals**, **weight updates**, **learned associations**â€”operate in both silicon and neurons.\n",
    "\n",
    "**Clinical relevance:**  \n",
    "If dopamine bursts are hijacked (e.g., by addictive drugs or maladaptive cues), this same learning loop can over-train the NAcc, inflating \"wanting\" for harmful stimuli. Understanding the mechanism is the first step toward interventions that re-wire these associations.\n",
    "\n",
    "---\n",
    "\n",
    "**Take a moment to look back at your three plotsâ€”each one is a puzzle piece showing *when* (timecourse), *how much* (box plot), and *how certain* (bootstrap CI) the NAcc responds to anticipated rewards.**\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
