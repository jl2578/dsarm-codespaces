{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c9a5da7",
   "metadata": {},
   "source": [
    "# Exercise 8: Cues, Wanting, and the Reward System\n",
    "## A quick look at the MID task\n",
    "\n",
    "In the **Monetary Incentive Delay (MID)** task:\n",
    "\n",
    "1. Participants see a cue that signals a possible reward, neutral outcome, or loss.  \n",
    "2. They respond quickly to a target to try to earn money (or avoid losing it).  \n",
    "3. We focus on the **cue period** to study *wanting* (motivational salience) rather than *liking*.  \n",
    "\n",
    "> **See â€œGuide to Exercise 8â€ slides** for a stepâ€‘byâ€‘step demo of the MID timing, trial types, and expected brain responses.  \n",
    "> **Reminder:** PSC is BOLD percentâ€‘signal change (bloodâ€‘flow proxy), not dopamine.\n",
    "\n",
    "---\n",
    "\n",
    "## What you will do in this notebook (and why)\n",
    "\n",
    "### 1. **QC Anatomy**  \n",
    "You will load brain images and verify the alignment of your region of interest (ROI)â€”the nucleus accumbens (NAcc).  \n",
    "**Why?**  \n",
    "âœ… To make sure the mask correctly covers the NAcc (more on the mask below). If the mask is off, any measurements from it would not represent true NAcc activity.\n",
    "\n",
    "#### Exploring the NAcc in the ABCD Data Dictionary\n",
    "\n",
    "For a deeper understanding of the nucleus accumbens (NAcc), look up the following metrics in the ABCD data dictionary and visualize them using the Brain Atlas Visualizer:\n",
    "https://abcd.deapscience.com/#/my-datasets/create-dataset\n",
    "\n",
    "1. **mr_y_smri__vol__aseg__ab__lh_sum (and _rh_sum)**\n",
    "   - **What it measures:** Total volume (mmÂ³) of the left/right nucleus accumbens from FreeSurferâ€™s subcortical segmentation.\n",
    "   - **Why itâ€™s useful:** This is the classic structural metricâ€”literally the size of the NAcc. Itâ€™s stable, easy to interpret, and visually clear when you explore the region in the ABCD Brain Atlas Visualizer.\n",
    "\n",
    "2. **mr_y_smri__t1__aseg__ab__lh_mean (and _rh_mean)**\n",
    "   - **What it measures:** Mean T1-weighted intensity within the NAcc (left/right).\n",
    "   - **Why itâ€™s useful:** This reflects tissue contrast and integrity. It isnâ€™t a â€œsizeâ€ measure but a signal measure related to microstructural properties (e.g., myelination, iron content, water density). It provides a complementary way of looking at NAcc structure beyond just volume.\n",
    "---\n",
    "\n",
    "### 2. **Extract NAcc Time-Series**  \n",
    "You will extract the BOLD signal (functional MRI activation) from the NAcc across time. â€œBloodâ€‘Oxygenâ€‘Levelâ€‘Dependent (BOLD) signalâ€: this is a measure of blood flow to a brain region, which we use as a proxy for neural activity. \n",
    "\n",
    "**Why?**  \n",
    "âœ… To isolate the activity from our key brain region, so we can later connect its behavior to cue periods and trial events.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Build a Trial Table**  \n",
    "You will build a tidy trialâ€‘level table for **cue trials only**, with reward vs neutral labels.  \n",
    "**Why?**  \n",
    "âœ… A clean table makes it easy to compare conditions and plot results consistently across ROIs.  \n",
    "ğŸ§  The **incentiveâ€‘salience hypothesis** proposes that dopamine transforms neutral cues into â€œwantedâ€ signals, giving them motivational power to drive behavior.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Visualizations**  \n",
    "You will generate several figures:  \n",
    "- Cueâ€‘locked time series  \n",
    "- Box plots of cueâ€‘window means  \n",
    "- Coupling scatter and a tiny summary table  \n",
    "\n",
    "**Why?**  \n",
    "âœ… Different plots let you see the data from multiple perspectives: central tendency, spread, and brain location.  \n",
    "âœ… Visual summaries make it easier to compare ROIs and conditions.\n",
    "\n",
    "---\n",
    "\n",
    "Letâ€™s get started! ğŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905d2691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Import Libraries & Configure Environment\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Core libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# fMRI analysis\n",
    "from nilearn import image, masking\n",
    "from nilearn.image import resample_to_img\n",
    "from nilearn.masking import apply_mask\n",
    "\n",
    "# Interactive widgets\n",
    "from ipywidgets import interact\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Network utilities (for data download)\n",
    "import urllib.request\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Configuration\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Display plots inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_theme(context=\"notebook\", style=\"whitegrid\", palette=\"muted\", font_scale=1.2)\n",
    "\n",
    "# Create output folder for figures\n",
    "Path(\"figs\").mkdir(exist_ok=True)\n",
    "\n",
    "print(\"âœ… Environment configured successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff413962",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Source, Citation & Folder Layout\n",
    "\n",
    "**ğŸš¨ TEAMWORK NOTE (read carefully!)**  \n",
    "You can work with any of the four available subjects:\n",
    "- **Subject 06:** set `SUBJECT = \"sub-06\"`  \n",
    "- **Subject 09:** set `SUBJECT = \"sub-09\"`  \n",
    "- **Subject 11:** set `SUBJECT = \"sub-11\"`  \n",
    "- **Subject 14:** set `SUBJECT = \"sub-14\"`  \n",
    "\n",
    "In this exercise we use **real fMRI data** from the Adolescent Health and Development in Context (AHDC) study, publicly available on OpenNeuro:\n",
    "\n",
    "> Baldwin M. Way, Christopher R. Browning, Dylan D. Wagner, Jodi L. Ford, Bethany Boettner & Ping Bai (2025).  \n",
    "> _Structural and functional MRI dataset from the Adolescent Health and Development in Context (AHDC) study in Columbus, Ohio._  \n",
    "> OpenNeuro [Dataset] doi:10.18112/openneuro.ds005901.v1.0.0  \n",
    "> https://github.com/OpenNeuroDatasets/ds005901\n",
    "\n",
    "This dataset was collected as part of a **longitudinal neuroimaging study of adolescent health and development**. Participants completed surveys, smartphone-based ecological momentary assessments, and MRI scans across multiple waves. One aim was to understand how **community exposures and reward processes** shape brain function and substance use risk.\n",
    "\n",
    "We'll focus on the **Monetary Incentive Delay (MID)** task, which measures reward anticipation and cue-related responses. You can choose to analyze any of the four subjects' data from the first MID run.\n",
    "\n",
    "> **Before you begin, set `SUBJECT = \"sub-06\"`, `\"sub-09\"`, `\"sub-11\"`, or `\"sub-14\"`** in the code cell below.\n",
    "\n",
    "Each subject's folder contains:  \n",
    "- a 4D BOLD fMRI volume:  \n",
    "  `sub-06_task-mid_run-01_bold.nii.gz`  \n",
    "- its trial timing file:  \n",
    "  `sub-06_task-mid_run-01_events.tsv`  \n",
    "- (you'll also need the bilateral NAcc ROI mask: `nacc_bilateral_mask.nii`, placed in the `data/` folder)\n",
    "\n",
    "**Expected directory structure (this repo):**\n",
    "\n",
    "```\n",
    "Exercise8/\n",
    "â”œâ”€â”€ Exercise8.ipynb â† This notebook\n",
    "â”œâ”€â”€ figs/ â† Saved figures will go here\n",
    "â””â”€â”€ data/\n",
    "    â”œâ”€â”€ nacc_bilateral_mask.nii\n",
    "    â”œâ”€â”€ qc_nacc_roi_alignment.png â† Static QC image (if provided)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ea4e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 0. Data folder constants\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Data will be stored in the 'data' subfolder relative to this notebook\n",
    "# This works whether the notebook is opened directly or from the repo root\n",
    "DATA_ROOT = Path(\"data\")\n",
    "\n",
    "print(f\"ğŸ“ Data root: {DATA_ROOT.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef57f72",
   "metadata": {},
   "source": [
    "## Select Your Subject\n",
    "\n",
    "Choose which subject's data you'd like to analyze. Available subjects: sub-06, sub-09, sub-11, sub-14.\n",
    "\n",
    "> **Set `SUBJECT = \"sub-06\"`, `\"sub-09\"`, `\"sub-11\"`, or `\"sub-14\"`** in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb19301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to \"sub-06\", \"sub-09\", \"sub-11\", or \"sub-14\" before you start!\n",
    "\n",
    "SUBJECT = \"sub-06\"\n",
    "\n",
    "# Map classroom-friendly IDs to OpenNeuro dataset IDs\n",
    "SUBJECT_MAP = {\n",
    "    \"sub-06\": \"sub-s006\",\n",
    "    \"sub-09\": \"sub-s009\",\n",
    "    \"sub-11\": \"sub-s011\",\n",
    "    \"sub-14\": \"sub-s014\",\n",
    "}\n",
    "\n",
    "if not isinstance(SUBJECT, str):\n",
    "    raise ValueError(\"SUBJECT must be a string.\")\n",
    "\n",
    "subject_norm = SUBJECT.strip().lower()\n",
    "\n",
    "# Accept common variants and normalize:\n",
    "# - sub-06 / sub-09 / sub-11 / sub-14 (preferred classroom labels)\n",
    "# - sub-006 / sub-009 / sub-011 / sub-014\n",
    "# - sub-s006 / sub-s009 / sub-s011 / sub-s014 (direct dataset IDs)\n",
    "if subject_norm in SUBJECT_MAP:\n",
    "    DATASET_SUBJECT = SUBJECT_MAP[subject_norm]\n",
    "elif subject_norm.startswith(\"sub-\") and subject_norm[4:].isdigit():\n",
    "    n = int(subject_norm[4:])\n",
    "    candidate = f\"sub-{n:02d}\"\n",
    "    if candidate in SUBJECT_MAP:\n",
    "        DATASET_SUBJECT = SUBJECT_MAP[candidate]\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Only subjects 06, 09, 11, and 14 are available in this exercise.\"\n",
    "        )\n",
    "elif subject_norm.startswith(\"sub-s\") and subject_norm[5:].isdigit():\n",
    "    n = int(subject_norm[5:])\n",
    "    candidate = f\"sub-{n:02d}\"\n",
    "    if candidate in SUBJECT_MAP:\n",
    "        DATASET_SUBJECT = subject_norm\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Only subjects 06, 09, 11, and 14 are available in this exercise.\"\n",
    "        )\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"SUBJECT must be one of 'sub-06', 'sub-09', 'sub-11', 'sub-14' (or variants like 'sub-006' / 'sub-s006').\"\n",
    "    )\n",
    "\n",
    "# Pre-defined file paths (dataset uses sub-sXXX folders/files)\n",
    "FUNC_DIR = DATA_ROOT / DATASET_SUBJECT / \"func\"\n",
    "BOLD_PATH = FUNC_DIR / f\"{DATASET_SUBJECT}_task-mid_run-01_bold.nii.gz\"\n",
    "EVENT_PATH = FUNC_DIR / f\"{DATASET_SUBJECT}_task-mid_run-01_events.tsv\"\n",
    "NACC_MASK_PATH = DATA_ROOT / \"nacc_bilateral_mask.nii\"\n",
    "\n",
    "FIG_DIR = Path(\"figs\")\n",
    "FIG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Selected subject (input):\", SUBJECT)\n",
    "print(\"Selected subject (dataset ID):\", DATASET_SUBJECT)\n",
    "print(\"  BOLD (compressed) â†’\", BOLD_PATH)\n",
    "print(\"  EVENTS â†’\", EVENT_PATH)\n",
    "print(\"  NAcc MASK â†’\", NACC_MASK_PATH)\n",
    "print(\"  FIGS â†’\", FIG_DIR.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58e0a45",
   "metadata": {},
   "source": [
    "## Create a VTA Sphere Mask (in BOLD space)\n",
    "\n",
    "We'll build a small spherical ROI for the **ventral tegmental area (VTA)** directly inside the notebook. Run the download cell first so the BOLD file exists.\n",
    "\n",
    "- **VTA center (MNI):** $(-4, -15, -9)$  \n",
    "- **Radius:** 5 mm (small enough to target midbrain while still capturing a few voxels)\n",
    "\n",
    "This mask is created in the same voxel space as your BOLD image, then saved to `data/vta_sphere_mask.nii.gz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Robust data download (OpenNeuro snapshot URL + direct S3 fallback; GitHub fallback for TSV only)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError, URLError\n",
    "\n",
    "DATASET  = \"ds005901\"\n",
    "SNAPSHOT = \"1.0.0\"  # used by OpenNeuro snapshot URLs\n",
    "\n",
    "# Ensure output folders exist early\n",
    "FUNC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Helpers\n",
    "# --------------------------------------------------------------------\n",
    "def is_gzip_file(path: Path) -> bool:\n",
    "    \"\"\"Return True if file exists and has gzip magic bytes.\"\"\"\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            return f.read(2) == b\"\\x1f\\x8b\"\n",
    "    except OSError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def download_one(url: str, dest: Path) -> bool:\n",
    "    \"\"\"Download URL to dest, streaming in chunks. Returns True on success.\"\"\"\n",
    "    try:\n",
    "        dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with urllib.request.urlopen(url) as r, open(dest, \"wb\") as f:\n",
    "            shutil.copyfileobj(r, f, length=1024 * 1024)\n",
    "        return True\n",
    "    except (HTTPError, URLError) as e:\n",
    "        print(f\"   âš ï¸  failed: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  failed: {type(e).__name__}: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def download_with_fallback(urls: list[str], dest: Path) -> Path | None:\n",
    "    \"\"\"Try URLs in order; returns dest if downloaded, else None.\"\"\"\n",
    "    for i, url in enumerate(urls, start=1):\n",
    "        print(f\"â¬‡ï¸  [{i}/{len(urls)}] {dest.name} â† {url}\")\n",
    "        if download_one(url, dest):\n",
    "            print(\"   â€¦downloaded\")\n",
    "            return dest\n",
    "    return None\n",
    "\n",
    "\n",
    "def ensure_openneuro_py() -> None:\n",
    "    \"\"\"Install openneuro-py once per session if needed.\"\"\"\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            [\"openneuro-py\", \"--help\"],\n",
    "            stdout=subprocess.DEVNULL,\n",
    "            stderr=subprocess.DEVNULL,\n",
    "            check=True,\n",
    "        )\n",
    "    except Exception:\n",
    "        subprocess.run([\"python3\", \"-m\", \"pip\", \"install\", \"-q\", \"openneuro-py\"], check=True)\n",
    "\n",
    "\n",
    "def openneuro_py_download(relpath: str, target_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    relpath example: 'sub-s006/func/sub-s006_task-mid_run-01_bold.nii.gz'\n",
    "    Downloads into target_dir/..., preserving the relpath structure.\n",
    "    \"\"\"\n",
    "    ensure_openneuro_py()\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"openneuro-py\",\n",
    "            \"download\",\n",
    "            f\"--dataset={DATASET}\",\n",
    "            f\"--target-dir={target_dir}\",\n",
    "            f\"--include={relpath}\",\n",
    "        ],\n",
    "        check=True,\n",
    "    )\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Build paths + URLs\n",
    "# --------------------------------------------------------------------\n",
    "events_fname = EVENT_PATH.name\n",
    "bold_fname   = BOLD_PATH.name\n",
    "\n",
    "evt_path     = EVENT_PATH\n",
    "bold_path_gz = BOLD_PATH\n",
    "\n",
    "# OpenNeuro \"snapshot\" URLs (sometimes return 502 during outages)\n",
    "openneuro_evt = (\n",
    "    f\"https://openneuro.org/crn/datasets/{DATASET}/snapshots/{SNAPSHOT}/files/\"\n",
    "    f\"{DATASET_SUBJECT}:func:{events_fname}?download=1\"\n",
    ")\n",
    "openneuro_bold = (\n",
    "    f\"https://openneuro.org/crn/datasets/{DATASET}/snapshots/{SNAPSHOT}/files/\"\n",
    "    f\"{DATASET_SUBJECT}:func:{bold_fname}?download=1\"\n",
    ")\n",
    "\n",
    "# Direct S3 URLs (often work even if OpenNeuro web/API is down)\n",
    "s3_evt  = f\"https://s3.amazonaws.com/openneuro.org/{DATASET}/{DATASET_SUBJECT}/func/{events_fname}\"\n",
    "s3_bold = f\"https://s3.amazonaws.com/openneuro.org/{DATASET}/{DATASET_SUBJECT}/func/{bold_fname}\"\n",
    "\n",
    "# GitHub raw: OK for TSV; DO NOT use GitHub raw for .nii.gz (git-annex pointer)\n",
    "github_evt = f\"https://github.com/OpenNeuroDatasets/{DATASET}/raw/main/{DATASET_SUBJECT}/func/{events_fname}\"\n",
    "\n",
    "events_urls = [openneuro_evt, s3_evt, github_evt]\n",
    "bold_urls   = [openneuro_bold, s3_bold]\n",
    "\n",
    "print(f\"ğŸ” Checking data files for {SUBJECT} (dataset: {DATASET_SUBJECT})â€¦\")\n",
    "\n",
    "# EVENTS (idempotent)\n",
    "if evt_path.exists() and evt_path.stat().st_size > 0:\n",
    "    print(f\"âœ… {events_fname} already exists, skipping download.\")\n",
    "else:\n",
    "    if download_with_fallback(events_urls, evt_path) is None:\n",
    "        print(\"âŒ Events download failed.\")\n",
    "\n",
    "# BOLD (idempotent + gzip check)\n",
    "if bold_path_gz.exists() and is_gzip_file(bold_path_gz):\n",
    "    print(f\"âœ… {bold_fname} already exists and is gzip, skipping download.\")\n",
    "else:\n",
    "    bold_gz = download_with_fallback(bold_urls, bold_path_gz)\n",
    "\n",
    "    # If somehow a non-gzip file landed at the destination, delete it\n",
    "    if bold_gz and not is_gzip_file(bold_gz):\n",
    "        print(\"ğŸ§ª The downloaded BOLD file is not gzip. Deleting it.\")\n",
    "        try:\n",
    "            os.remove(bold_gz)\n",
    "        except OSError:\n",
    "            pass\n",
    "        bold_gz = None\n",
    "\n",
    "    # If direct URL routes failed, try openneuro-py (may also fail during outages)\n",
    "    if bold_gz is None:\n",
    "        try:\n",
    "            print(\"ğŸ” Trying OpenNeuro via openneuro-pyâ€¦\")\n",
    "            rel = f\"{DATASET_SUBJECT}/func/{bold_fname}\"\n",
    "            openneuro_py_download(rel, target_dir=str(DATA_ROOT))\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ openneuro-py download failed: {e}\")\n",
    "\n",
    "print(\"\\n======================================================================\")\n",
    "print(\"ğŸ“ File paths:\")\n",
    "print(f\"  BOLD:   {BOLD_PATH} (exists: {BOLD_PATH.exists()})\")\n",
    "print(f\"  EVENTS: {EVENT_PATH} (exists: {EVENT_PATH.exists()})\")\n",
    "print(f\"  NAcc MASK: {NACC_MASK_PATH} (exists: {NACC_MASK_PATH.exists()})\")\n",
    "\n",
    "assert BOLD_PATH.exists() and is_gzip_file(BOLD_PATH), \"Missing or invalid BOLD .nii.gz.\"\n",
    "assert EVENT_PATH.exists(), \"Missing events.tsv.\"\n",
    "assert NACC_MASK_PATH.exists(), \"Missing NAcc mask (data/nacc_bilateral_mask.nii).\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3149166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "VTA_MNI = (-4, -15, -9)\n",
    "VTA_RADIUS_MM = 5\n",
    "\n",
    "if not BOLD_PATH.exists():\n",
    "    raise FileNotFoundError(\"BOLD file not found. Run the download cell above first.\")\n",
    "\n",
    "bold_img = nib.load(str(BOLD_PATH))\n",
    "affine = bold_img.affine\n",
    "shape = bold_img.shape[:3]\n",
    "\n",
    "# Build a voxel-wise distance map in MNI space\n",
    "ijk = np.indices(shape).reshape(3, -1).T\n",
    "xyz = nib.affines.apply_affine(affine, ijk)\n",
    "center = np.array(VTA_MNI, dtype=float)\n",
    "dist_mm = np.linalg.norm(xyz - center, axis=1)\n",
    "\n",
    "mask_data = (dist_mm <= VTA_RADIUS_MM).reshape(shape).astype(\"uint8\")\n",
    "\n",
    "VTA_MASK_PATH = DATA_ROOT / \"vta_sphere_mask.nii.gz\"\n",
    "mask_img = nib.Nifti1Image(mask_data, affine)\n",
    "nib.save(mask_img, str(VTA_MASK_PATH))\n",
    "\n",
    "print(f\"âœ… VTA mask saved: {VTA_MASK_PATH}\")\n",
    "print(f\"   Center (MNI): {VTA_MNI}, radius: {VTA_RADIUS_MM} mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39574601",
   "metadata": {},
   "source": [
    "## 1. QC Anatomy & File Sanity Checks\n",
    "\n",
    "We will generate two QC overlays and save them to `figs/`:\n",
    "- `0_qc_nacc.png`: mean functional image + NAcc mask\n",
    "- `0_qc_vta.png`: mean functional image + VTA sphere mask\n",
    "\n",
    "Check that both ROIs sit in the expected anatomical locations before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e480eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# QC: file checks + generate NAcc and VTA ROI overlays on mean functional\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nilearn import image, plotting\n",
    "from PIL import Image as PILImage\n",
    "from IPython.display import display\n",
    "\n",
    "print(f\"ğŸ“Š Analyzing: {SUBJECT}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  BOLD   exists? {BOLD_PATH.exists()}  -> {BOLD_PATH}\")\n",
    "print(f\"  EVENTS exists? {EVENT_PATH.exists()} -> {EVENT_PATH}\")\n",
    "print(f\"  NAcc  exists? {NACC_MASK_PATH.exists()}  -> {NACC_MASK_PATH}\")\n",
    "print(f\"  VTA   exists? {VTA_MASK_PATH.exists()}  -> {VTA_MASK_PATH}\")\n",
    "\n",
    "# Stop early if anything required is missing\n",
    "missing_files = []\n",
    "if not BOLD_PATH.exists():\n",
    "    missing_files.append((\"BOLD\", BOLD_PATH))\n",
    "if not EVENT_PATH.exists():\n",
    "    missing_files.append((\"EVENTS\", EVENT_PATH))\n",
    "if not NACC_MASK_PATH.exists():\n",
    "    missing_files.append((\"NAcc_MASK\", NACC_MASK_PATH))\n",
    "if not VTA_MASK_PATH.exists():\n",
    "    missing_files.append((\"VTA_MASK\", VTA_MASK_PATH))\n",
    "\n",
    "if missing_files:\n",
    "    print(\"\\nâŒ Missing required files:\")\n",
    "    for label, path in missing_files:\n",
    "        print(f\"  - {label}: {path}\")\n",
    "\n",
    "    print(\"\\nFixes:\")\n",
    "    print(\"  - Re-run the download cell above to fetch BOLD and EVENTS.\")\n",
    "    print(\"  - Confirm the instructor-provided NAcc mask is present in data/.\")\n",
    "    print(\"  - Re-run the VTA mask cell to regenerate the VTA sphere.\")\n",
    "    raise FileNotFoundError(\"Required files missing; cannot generate QC figures.\")\n",
    "\n",
    "print(\"\\nâœ… All required files found. Generating QC overlay figures...\")\n",
    "\n",
    "# Helper: compute mask center-of-mass (mm) for sensible cut coordinates\n",
    "def mask_center_mm(mask_path):\n",
    "    m = nib.load(str(mask_path))\n",
    "    data = m.get_fdata() > 0\n",
    "    ijk = np.argwhere(data)\n",
    "    if ijk.size == 0:\n",
    "        return (0.0, 0.0, 0.0)\n",
    "    com_ijk = ijk.mean(axis=0)\n",
    "    com_xyz = nib.affines.apply_affine(m.affine, com_ijk)\n",
    "    return (float(com_xyz[0]), float(com_xyz[1]), float(com_xyz[2]))\n",
    "\n",
    "# Helper: parse task/run from filename for a clearer title\n",
    "def parse_task_run(fname):\n",
    "    task = None\n",
    "    run = None\n",
    "    for part in fname.split(\"_\"):\n",
    "        if part.startswith(\"task-\"):\n",
    "            task = part.replace(\"task-\", \"\")\n",
    "        if part.startswith(\"run-\"):\n",
    "            run = part.replace(\"run-\", \"\")\n",
    "    return task, run\n",
    "\n",
    "task, run = parse_task_run(BOLD_PATH.name)\n",
    "task_str = \"MID task\" if task == \"mid\" else (f\"task-{task}\" if task else \"task\")\n",
    "run_str = f\"run-{run}\" if run else \"run\"\n",
    "\n",
    "cut_coords_nacc = mask_center_mm(NACC_MASK_PATH)\n",
    "cut_coords_vta = mask_center_mm(VTA_MASK_PATH)\n",
    "\n",
    "qc_nacc_path = FIG_DIR / \"0_qc_nacc.png\"\n",
    "qc_vta_path = FIG_DIR / \"0_qc_vta.png\"\n",
    "\n",
    "# Always generate (overwrite) so the QC images are real, not placeholders\n",
    "mean_func = image.mean_img(str(BOLD_PATH))\n",
    "\n",
    "# QC Figure 1: NAcc overlay\n",
    "disp_nacc = plotting.plot_roi(\n",
    "    str(NACC_MASK_PATH),\n",
    "    bg_img=mean_func,\n",
    "    title=f\"QC: NAcc ROI alignment (mean fMRI, {SUBJECT}, {task_str}, {run_str})\",\n",
    "    display_mode=\"ortho\",\n",
    "    cut_coords=cut_coords_nacc,\n",
    "    draw_cross=True,\n",
    ")\n",
    "disp_nacc.savefig(str(qc_nacc_path), dpi=250)\n",
    "disp_nacc.close()\n",
    "\n",
    "# QC Figure 2: VTA overlay\n",
    "disp_vta = plotting.plot_roi(\n",
    "    str(VTA_MASK_PATH),\n",
    "    bg_img=mean_func,\n",
    "    title=f\"QC: VTA sphere alignment (mean fMRI, {SUBJECT}, {task_str}, {run_str})\",\n",
    "    display_mode=\"ortho\",\n",
    "    cut_coords=cut_coords_vta,\n",
    "    draw_cross=True,\n",
    ")\n",
    "disp_vta.savefig(str(qc_vta_path), dpi=250)\n",
    "disp_vta.close()\n",
    "\n",
    "print(f\"\\nğŸ“ QC figures saved to:\")\n",
    "print(f\"  - {qc_nacc_path}\")\n",
    "print(f\"  - {qc_vta_path}\")\n",
    "print(f\"   NAcc cut coords (mm): x={cut_coords_nacc[0]:.1f}, y={cut_coords_nacc[1]:.1f}, z={cut_coords_nacc[2]:.1f}\")\n",
    "print(f\"   VTA  cut coords (mm): x={cut_coords_vta[0]:.1f}, y={cut_coords_vta[1]:.1f}, z={cut_coords_vta[2]:.1f}\")\n",
    "\n",
    "display(PILImage.open(qc_nacc_path))\n",
    "display(PILImage.open(qc_vta_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96518fe",
   "metadata": {},
   "source": [
    "### QC Checklist\n",
    "\n",
    "- BOLD, EVENTS, NAcc mask, and VTA mask files exist.\n",
    "- NAcc overlay sits in ventral striatum.\n",
    "- VTA sphere sits in the midbrain; if it looks off-target, adjust `VTA_MNI` or `VTA_RADIUS_MM` and re-run the VTA cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233d45e1",
   "metadata": {},
   "source": [
    "## 2. Extract NAcc Time-Series\n",
    "\n",
    "Before we dive in, let's simplify **TR** (Repetition Time):\n",
    "\n",
    "> **TR = the interval between \"snapshots.\"**  \n",
    "> Every TR seconds (e.g. 2 s) the scanner takes one full 3D \"photo\" of your brain. When we want the BOLD signal right after an event, we convert the event time (in seconds) into which snapshot number (TR index) to pull.\n",
    "\n",
    "In the cell below we use a helper function `extract_psc()` that:\n",
    "\n",
    "1. **Loads** the 4D BOLD time-series image\n",
    "2. **Resamples the ROI mask** to match the BOLD data's voxel grid and coordinate system  \n",
    "   ğŸ§  This ensures each mask voxel correctly overlaps with corresponding BOLD voxels\n",
    "3. **Applies the mask** to extract BOLD values from NAcc voxels across all time points  \n",
    "   ğŸ¯ Isolates the signal over time from just the NAccâ€”ignoring everything else in the brain\n",
    "4. **Averages across voxels** at each TR to produce a single NAcc time-series  \n",
    "5. **Converts to percent-signal-change (PSC)** for standardized, interpretable units\n",
    "\n",
    "The function returns both:\n",
    "- `nacc_psc`: percent-signal-change time-series (for analysis)\n",
    "- `nacc_ts`: raw signal time-series (for reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a223100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 2. Extract ROI time-series (PSC)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def extract_psc(bold_path, mask_path, roi_name):\n",
    "    \"\"\"\n",
    "    Extract percent-signal-change time-series from an ROI.\n",
    "\n",
    "    Returns a dict with:\n",
    "      - roi_name\n",
    "      - raw_ts\n",
    "      - psc_ts\n",
    "      - baseline_raw\n",
    "    \"\"\"\n",
    "    bold_img = image.load_img(str(bold_path))\n",
    "\n",
    "    # Resample mask to BOLD space (nearest-neighbor keeps it binary)\n",
    "    mask_res = resample_to_img(\n",
    "        source_img=str(mask_path),\n",
    "        target_img=bold_img,\n",
    "        interpolation=\"nearest\"\n",
    "    )\n",
    "\n",
    "    # apply_mask returns array of shape (n_volumes, n_voxels)\n",
    "    roi_vox_ts = apply_mask(bold_img, mask_res)\n",
    "    raw_ts = roi_vox_ts.mean(axis=1)\n",
    "\n",
    "    baseline_raw = float(raw_ts.mean())\n",
    "    psc_ts = 100 * (raw_ts - baseline_raw) / baseline_raw\n",
    "\n",
    "    print(f\"{roi_name}: {len(psc_ts)} TRs, baseline = {baseline_raw:.1f}\")\n",
    "\n",
    "    return {\n",
    "        \"roi_name\": roi_name,\n",
    "        \"raw_ts\": raw_ts,\n",
    "        \"psc_ts\": psc_ts,\n",
    "        \"baseline_raw\": baseline_raw,\n",
    "    }\n",
    "\n",
    "# 2a) Extract NAcc and VTA time-series\n",
    "nacc = extract_psc(BOLD_PATH, NACC_MASK_PATH, \"NAcc\")\n",
    "vta = extract_psc(BOLD_PATH, VTA_MASK_PATH, \"VTA\")\n",
    "\n",
    "# 2b) Quick peek: show first k rows of the NAcc PSC time-series in a table\n",
    "nacc_psc = nacc[\"psc_ts\"]\n",
    "df_nacc = pd.DataFrame(nacc_psc, columns=[\"psc_nacc\"])\n",
    "\n",
    "# interactive slider to choose how many rows to display\n",
    "interact(\n",
    "    lambda k: df_nacc.head(k),\n",
    "    k=(1, min(20, len(df_nacc)), 1)  # slider from 1 up to 20 (or total TRs if fewer)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d576f363",
   "metadata": {},
   "source": [
    "### What just happened?\n",
    "\n",
    "- **Raw â†’ PSC:** We calculated the average ROI signal across the entire run (`baseline_raw`), then converted each TRâ€™s mean activation into **percent-signal-change** (`psc_ts`). Now â€œ0 %â€ means no change from baseline, and â€œ+1 %â€ means a 1 % increase.\n",
    "- **What is PSC?** **Percent-Signal-Change (PSC)** expresses each TRâ€™s BOLD signal as a percentage change from its baseline, effectively measuring the percent change in blood flow (and thus neural activity) within your ROI (Brain Region of Interest).\n",
    "- **Interactive preview:** The slider lets you inspect the first k rows of the NAcc PSC time-series. Try moving it between 1 and 20 (or more) to see how NAcc activation evolves over those snapshots.\n",
    "- **Why PSC?** Converting to percent-signal-change puts all activation values on an intuitive, comparable scaleâ€”standard practice in fMRIâ€”so your subsequent plots speak in â€œpercent changeâ€ rather than arbitrary intensities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ab73a3",
   "metadata": {},
   "source": [
    "## 3. Build a Trial Table (Cue Only)\n",
    "\n",
    "In this step we:\n",
    "\n",
    "- **Load** the MID events file and read each trial's onset time (in seconds) and `trial_type`.\n",
    "- **Extract** TR from the BOLD header and print it.\n",
    "- **Keep only cue trials** (trial_type starts with `Cue`, case-insensitive).\n",
    "- **Label conditions** as `reward` or `neutral` using robust text matching.\n",
    "- **Compute a PSC window mean** for each cue and build a tidy trial table (`trial_df`).\n",
    "\n",
    "At the end you'll have one long-format table with one row per trial per ROI (NAcc + VTA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be00f052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 3. Build a trial-level table from cue events (PSC window mean)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# 3a) Load events.tsv\n",
    "events = pd.read_csv(str(EVENT_PATH), sep='\\t')\n",
    "print(\"events.columns:\", list(events.columns))\n",
    "\n",
    "unique_types = pd.Series(events[\"trial_type\"].astype(str).unique())\n",
    "print(\"first unique trial_type values:\")\n",
    "print(unique_types.head(20).to_list())\n",
    "\n",
    "# 3b) Get TR from header\n",
    "TR = image.load_img(str(BOLD_PATH)).header.get_zooms()[3]\n",
    "print(f\"Repetition time (TR) = {TR} s\")\n",
    "\n",
    "# 3c) Cue-only subset (case-insensitive)\n",
    "trial_type = events[\"trial_type\"].astype(str)\n",
    "cue_mask = trial_type.str.lower().str.startswith(\"cue\", na=False)\n",
    "cue_events = events.loc[cue_mask].copy()\n",
    "\n",
    "# 3d) Condition labels (robust)\n",
    "trial_type_cue = cue_events[\"trial_type\"].astype(str)\n",
    "is_reward = trial_type_cue.str.contains(\"Reward|Gain\", case=False, na=False)\n",
    "is_neutral = trial_type_cue.str.contains(\"Neutral|Triangle\", case=False, na=False)\n",
    "\n",
    "cue_events = cue_events.loc[is_reward | is_neutral].copy()\n",
    "cue_events[\"condition\"] = np.where(\n",
    "    cue_events[\"trial_type\"].astype(str).str.contains(\"Reward|Gain\", case=False, na=False),\n",
    "    \"reward\",\n",
    "    \"neutral\",\n",
    ")\n",
    "\n",
    "# 3e) Trialwise PSC window mean helper\n",
    "def trial_window_mean(psc_ts, onset_s, TR, lag_trs=5, win_trs=2):\n",
    "    onset_tr = int(np.round(onset_s / TR))\n",
    "    start = onset_tr + lag_trs\n",
    "    end = start + win_trs\n",
    "    if start < 0 or end > len(psc_ts):\n",
    "        return np.nan\n",
    "    return float(np.nanmean(psc_ts[start:end]))\n",
    "\n",
    "# 3f) Build long-format trial_df (NAcc + VTA)\n",
    "rows = []\n",
    "for roi in [nacc, vta]:\n",
    "    roi_name = roi[\"roi_name\"]\n",
    "    psc_ts = roi[\"psc_ts\"]\n",
    "    for _, trial in cue_events.iterrows():\n",
    "        rows.append(\n",
    "            {\n",
    "                \"roi\": roi_name,\n",
    "                \"condition\": trial[\"condition\"],\n",
    "                \"onset_s\": float(trial[\"onset\"]),\n",
    "                \"psc_window_mean\": trial_window_mean(psc_ts, trial[\"onset\"], TR),\n",
    "            }\n",
    "        )\n",
    "\n",
    "trial_df = pd.DataFrame(rows)\n",
    "\n",
    "before = len(trial_df)\n",
    "trial_df = trial_df.dropna(subset=[\"psc_window_mean\"]).reset_index(drop=True)\n",
    "dropped = before - len(trial_df)\n",
    "print(f\"Dropped {dropped} trial rows with NaNs (out-of-range windows).\")\n",
    "\n",
    "print(\"trial_df preview:\")\n",
    "print(trial_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78569be7",
   "metadata": {},
   "source": [
    "**What this output tells us**:\n",
    "\n",
    "- The `events.columns` printout confirms the file loaded correctly.\n",
    "- The first unique `trial_type` values give a quick sanity check of the event labels.\n",
    "- The printed **TR** tells us how many seconds each volume represents.\n",
    "- `trial_df` is a tidy, long-format table with one row per trial per ROI (NAcc + VTA) for cue trials only.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e50b0e",
   "metadata": {},
   "source": [
    "### Quick Check: Mean PSC by Condition (NAcc + VTA)\n",
    "\n",
    "Now that `trial_df` is built, compute mean PSC for both ROIs on reward vs neutral cue trials.\n",
    "\n",
    "First try writing the code yourself before using AI help.\n",
    "\n",
    "Fill in code to compute:\n",
    "- `mean_reward_nacc`, `mean_neutral_nacc`\n",
    "- `mean_reward_vta`, `mean_neutral_vta`\n",
    "\n",
    "Then compute and print:\n",
    "- `delta_nacc = mean_reward_nacc - mean_neutral_nacc`\n",
    "- `delta_vta  = mean_reward_vta  - mean_neutral_vta`\n",
    "\n",
    "In 1-2 sentences: do NAcc and VTA show the same direction (sign) for Î”PSC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807684a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Student TO-DO: compute means for NAcc and VTA (cue trials only) ---\n",
    "mean_reward_nacc  = ...  # average NAcc PSC for reward cues\n",
    "mean_neutral_nacc = ...  # average NAcc PSC for neutral cues\n",
    "\n",
    "mean_reward_vta   = ...  # average VTA PSC for reward cues\n",
    "mean_neutral_vta  = ...  # average VTA PSC for neutral cues\n",
    "\n",
    "delta_nacc = mean_reward_nacc - mean_neutral_nacc\n",
    "delta_vta  = mean_reward_vta  - mean_neutral_vta\n",
    "\n",
    "print(\"NAcc delta PSC (Reward - Neutral) =\", delta_nacc)\n",
    "print(\"VTA  delta PSC (Reward - Neutral) =\", delta_vta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a458ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Student TO-DO: compute means for NAcc and VTA (cue trials only) ---\n",
    "mean_reward_nacc  = trial_df[(trial_df[\"roi\"] == \"NAcc\") & (trial_df[\"condition\"] == \"reward\")][\"psc_window_mean\"].mean()\n",
    "mean_neutral_nacc = trial_df[(trial_df[\"roi\"] == \"NAcc\") & (trial_df[\"condition\"] == \"neutral\")][\"psc_window_mean\"].mean()\n",
    "\n",
    "mean_reward_vta   = trial_df[(trial_df[\"roi\"] == \"VTA\") & (trial_df[\"condition\"] == \"reward\")][\"psc_window_mean\"].mean()\n",
    "mean_neutral_vta  = trial_df[(trial_df[\"roi\"] == \"VTA\") & (trial_df[\"condition\"] == \"neutral\")][\"psc_window_mean\"].mean()\n",
    "\n",
    "delta_nacc = mean_reward_nacc - mean_neutral_nacc\n",
    "delta_vta  = mean_reward_vta  - mean_neutral_vta\n",
    "\n",
    "print(\"NAcc delta PSC (Reward - Neutral) =\", delta_nacc)\n",
    "print(\"VTA  delta PSC (Reward - Neutral) =\", delta_vta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52d20d7",
   "metadata": {},
   "source": [
    "## 4.Â Visualisations\n",
    "\n",
    "Below are the key plots you will generate.  Each cell saves its figure into `figs/` so you can easily pull them into your writeâ€‘up. The **Figs** folder is in the same folder as this file alongside our datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fcfb6c",
   "metadata": {},
   "source": [
    "### 4a) Cue-Locked Timecourses (NAcc + VTA)\n",
    "\n",
    "We will plot cue-locked PSC timecourses for **NAcc** and **VTA** using the same window and baseline correction.\n",
    "\n",
    "Each figure shows:\n",
    "- Reward cue mean PSC vs neutral cue mean PSC\n",
    "- Shaded SEM\n",
    "\n",
    "Saved outputs:\n",
    "- `figs/4a_timecourse_cue_nacc.png`\n",
    "- `figs/4a_timecourse_cue_vta.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4062d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cue-locked timecourses for NAcc and VTA\n",
    "# Required inputs from earlier in the notebook\n",
    "missing = [name for name in [\"nacc\", \"vta\", \"cue_events\", \"TR\", \"FIG_DIR\"] if name not in globals()]\n",
    "if missing:\n",
    "    raise NameError(f\"Missing required variables: {missing}. Run the earlier data/epoch setup cells first.\")\n",
    "\n",
    "# Window: -2 TR to +14 TR\n",
    "win_pre, win_post = 2, 14\n",
    "\n",
    "def extract_epoch(ts, onset_s, TR, pre, post):\n",
    "    onset_tr = int(np.round(onset_s / TR))\n",
    "    idx = np.arange(onset_tr - pre, onset_tr + post)\n",
    "    valid = (idx >= 0) & (idx < len(ts))\n",
    "    out = np.full(idx.shape, np.nan, dtype=float)\n",
    "    out[valid] = ts[idx[valid]]\n",
    "    return out\n",
    "\n",
    "\n",
    "def baseline_correct(epochs, pre_trs):\n",
    "    base = np.nanmean(epochs[:, :pre_trs], axis=1, keepdims=True)\n",
    "    return epochs - base\n",
    "\n",
    "\n",
    "def plot_cue_timecourse(roi_dict, cue_events_df, TR, fig_path):\n",
    "    t = np.arange(-win_pre, win_post) * TR\n",
    "    psc_ts = roi_dict[\"psc_ts\"]\n",
    "\n",
    "    cue_reward_onsets = cue_events_df[cue_events_df[\"condition\"] == \"reward\"][\"onset\"].values\n",
    "    cue_neutral_onsets = cue_events_df[cue_events_df[\"condition\"] == \"neutral\"][\"onset\"].values\n",
    "\n",
    "    epochs_reward = np.vstack([extract_epoch(psc_ts, o, TR, win_pre, win_post) for o in cue_reward_onsets])\n",
    "    epochs_neutral = np.vstack([extract_epoch(psc_ts, o, TR, win_pre, win_post) for o in cue_neutral_onsets])\n",
    "\n",
    "    epochs_reward_bc = baseline_correct(epochs_reward, win_pre)\n",
    "    epochs_neutral_bc = baseline_correct(epochs_neutral, win_pre)\n",
    "\n",
    "    m_reward = np.nanmean(epochs_reward_bc, axis=0)\n",
    "    m_neutral = np.nanmean(epochs_neutral_bc, axis=0)\n",
    "    se_reward = np.nanstd(epochs_reward_bc, axis=0) / np.sqrt(np.sum(~np.isnan(epochs_reward_bc), axis=0))\n",
    "    se_neutral = np.nanstd(epochs_neutral_bc, axis=0) / np.sqrt(np.sum(~np.isnan(epochs_neutral_bc), axis=0))\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.plot(t, m_neutral, color=\"C0\", label=\"Neutral cue\")\n",
    "    plt.fill_between(t, m_neutral - se_neutral, m_neutral + se_neutral, color=\"C0\", alpha=0.2)\n",
    "    plt.plot(t, m_reward, color=\"C1\", label=\"Reward cue\")\n",
    "    plt.fill_between(t, m_reward - se_reward, m_reward + se_reward, color=\"C1\", alpha=0.2)\n",
    "    plt.axvline(0, color=\"k\", linestyle=\":\", linewidth=1)\n",
    "    plt.xlabel(\"Time from cue (s)\")\n",
    "    plt.ylabel(\"PSC (%)\")\n",
    "    plt.title(f\"Cue-locked PSC: {roi_dict['roi_name']}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(str(fig_path), dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "plot_cue_timecourse(nacc, cue_events, TR, FIG_DIR / \"4a_timecourse_cue_nacc.png\")\n",
    "plot_cue_timecourse(vta, cue_events, TR, FIG_DIR / \"4a_timecourse_cue_vta.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d44cdb7",
   "metadata": {},
   "source": [
    "### Interpreting the Cue-Locked Timecourses\n",
    "\n",
    "- Check that both ROIs show a cue-locked rise in PSC, with reward higher than neutral.\n",
    "- The peak should appear around 5 to 7 seconds after cue onset due to hemodynamic lag.\n",
    "- PSC is BOLD percent-signal change (blood-flow proxy), not dopamine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a387a9",
   "metadata": {},
   "source": [
    "### 4b) Box Plots: Cue Window Means (NAcc + VTA)\n",
    "\n",
    "We will plot Reward vs Neutral cue PSC window means for each ROI.\n",
    "\n",
    "Saved outputs:\n",
    "- `figs/4b_box_cue_nacc.png`\n",
    "- `figs/4b_box_cue_vta.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b92ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Box plots for cue window means (NAcc + VTA)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def plot_roi_boxplot(roi_name, fig_path):\n",
    "    roi_trials = trial_df[trial_df[\"roi\"] == roi_name].copy()\n",
    "    plt.figure(figsize=(5.5, 4))\n",
    "    sns.boxplot(\n",
    "        data=roi_trials,\n",
    "        x=\"condition\",\n",
    "        y=\"psc_window_mean\",\n",
    "        order=[\"neutral\", \"reward\"],\n",
    "        palette=[\"C0\", \"C1\"],\n",
    "        showfliers=False,\n",
    "    )\n",
    "    plt.xticks([0, 1], [\"Neutral cue\", \"Reward cue\"])\n",
    "    plt.ylabel(\"PSC (%)\")\n",
    "    plt.title(f\"{roi_name} PSC by cue type\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(str(fig_path), dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "plot_roi_boxplot(\"NAcc\", FIG_DIR / \"4b_box_cue_nacc.png\")\n",
    "plot_roi_boxplot(\"VTA\", FIG_DIR / \"4b_box_cue_vta.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f38bcb2",
   "metadata": {},
   "source": [
    "### 4c) Mesolimbic Coupling (Cue Trials)\n",
    "\n",
    "We will pair VTA and NAcc cue-window PSC per trial and visualize their coupling.\n",
    "\n",
    "Saved output:\n",
    "- `figs/4c_vta_nacc_coupling_cue.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d44a0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Coupling scatter: VTA vs NAcc (cue trials)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "wide_df = trial_df.pivot_table(\n",
    "    index=[\"onset_s\", \"condition\"],\n",
    "    columns=\"roi\",\n",
    "    values=\"psc_window_mean\",\n",
    "    aggfunc=\"mean\",\n",
    ").reset_index()\n",
    "\n",
    "wide_df = wide_df.dropna(subset=[\"NAcc\", \"VTA\"]).reset_index(drop=True)\n",
    "\n",
    "x = wide_df[\"VTA\"].values\n",
    "y = wide_df[\"NAcc\"].values\n",
    "\n",
    "coupling_r = np.nan\n",
    "if len(x) > 1:\n",
    "    coupling_r = float(np.corrcoef(x, y)[0, 1])\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.scatter(x, y, alpha=0.7, edgecolor=\"none\")\n",
    "plt.xlabel(\"VTA PSC (cue window mean)\")\n",
    "plt.ylabel(\"NAcc PSC (cue window mean)\")\n",
    "plt.title(f\"VTA-NAcc coupling (cue trials), r = {coupling_r:.2f}\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(FIG_DIR / \"4c_vta_nacc_coupling_cue.png\"), dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa0bd11",
   "metadata": {},
   "source": [
    "### Tiny Summary Table (Cue Trials)\n",
    "\n",
    "This table summarizes mean PSC by ROI and condition, plus delta PSC (Reward minus Neutral).\n",
    "Coupling r is reported from the scatterplot as a simple association and does not indicate causal direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dff18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiny summary table: ROI x (mean_reward, mean_neutral, delta_psc)\n",
    "summary = (\n",
    "    trial_df.groupby([\"roi\", \"condition\"])[\"psc_window_mean\"]\n",
    "           .mean()\n",
    "           .unstack(\"condition\")\n",
    "           .rename(columns={\"reward\": \"mean_reward\", \"neutral\": \"mean_neutral\"})\n",
    ")\n",
    "\n",
    "summary[\"delta_psc\"] = summary[\"mean_reward\"] - summary[\"mean_neutral\"]\n",
    "summary = summary.reset_index()\n",
    "\n",
    "# Pretty print (rounded)\n",
    "display(summary.round(4))\n",
    "\n",
    "# Ensure coupling_r exists (compute from trial_df if needed)\n",
    "if \"coupling_r\" not in globals():\n",
    "    wide_df = trial_df.pivot_table(\n",
    "        index=[\"onset_s\", \"condition\"],\n",
    "        columns=\"roi\",\n",
    "        values=\"psc_window_mean\",\n",
    "        aggfunc=\"mean\",\n",
    "    ).reset_index()\n",
    "    wide_df = wide_df.dropna(subset=[\"NAcc\", \"VTA\"]).reset_index(drop=True)\n",
    "\n",
    "    x = wide_df[\"VTA\"].values\n",
    "    y = wide_df[\"NAcc\"].values\n",
    "\n",
    "    coupling_r = np.nan\n",
    "    if len(x) > 1:\n",
    "        coupling_r = float(np.corrcoef(x, y)[0, 1])\n",
    "\n",
    "print(\"Coupling r (VTA vs NAcc, cue trials) =\", round(coupling_r, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91a3398",
   "metadata": {},
   "source": [
    "## Complete Individual Preparation Slides for Exercise 8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
